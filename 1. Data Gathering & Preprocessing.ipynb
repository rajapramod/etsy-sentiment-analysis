{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controlled-dialogue",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-university",
   "metadata": {},
   "source": [
    "The objective of this project is to build a machine learning model that classifies reviews entered by customers in an e-commerce website. \n",
    "\n",
    "Only reviews in English language are considered and reviews entered in other languages are omitted.\n",
    "\n",
    "To train the model with similar data, we use Amazon Review Dataset (given in the link: https://nijianmo.github.io/amazon/index.html). We download 'Clothing Shoes and Jewelry' dataset in .json format and has 32,292,099 ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-adelaide",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "- The downloaded dataset has 32 (and odd) million reviews. And out of many columns, we only consider `reviewText`, `overall` & `summary` columns.\n",
    "\n",
    "\n",
    "- We use only 1 million of the reviews at a time and create a CSV file having 4000 reviews of ratings 1, 2, 4 & 5 and 8000 reviews of rating 3.\n",
    "\n",
    "\n",
    "- We save each CSV file by `chunk_number.csv`. Thus we will have 33 chunks, having 24,000 reviews.\n",
    "\n",
    "\n",
    "- We then concatenate all 33 chunks to create `final_dataset.csv` with 7,92,000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "df = pd.read_json('Clothing_Shoes_and_Jewelry.json', lines=True, chunksize=1_000_000)\n",
    "\n",
    "counter=1\n",
    "for chunk in df:\n",
    "    chunk = chunk[['reviewText', 'overall', 'summary']]\n",
    "    df1 = chunk[chunk['overall']==1.0].sample(4000)\n",
    "    df2 = chunk[chunk['overall']==2.0].sample(4000)\n",
    "    df3 = chunk[chunk['overall']==3.0].sample(8000)\n",
    "    df4 = chunk[chunk['overall']==4.0].sample(4000)\n",
    "    df5 = chunk[chunk['overall']==5.0].sample(4000)\n",
    "    \n",
    "    combined_chunk = pd.concat([df1, df2, df3, df4, df5], axis=0, ignore_index=True)\n",
    "    combined_chunk.to_csv(str(counter)+'.csv', index=False)\n",
    "    print(f'{counter} out of 33')\n",
    "    counter += 1\n",
    "\n",
    "print('completed')\n",
    "\n",
    "files = glob.glob('*.csv')\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in files], axis=0, ignore_index=True)\n",
    "combined_csv.to_csv('final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-morning",
   "metadata": {},
   "source": [
    "Since we want only `reviewText`, `overall` & `summary` columns, we retain those and drop the other columns in the dataset. In other words, we are dropping 51 columns out of 54 columns in the dataset, retaining only 3 above said columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-rolling",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "qualified-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'overall', 'summary'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('final_dataset.csv', index_col=False)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-presence",
   "metadata": {},
   "source": [
    "We are classifying the reviews with ratings 1 & 2 as negative reviews and ratings with 4 & 5 as positive reviews. Thus, we need to drop all the rows (reviews) having 3 as ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_dataset.csv')\n",
    "df = df[df['overall'] != 3]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.to_csv('balanced_reviews.csv', index=False)\n",
    "\n",
    "# Adding a new column 'reviewPositive' where the value for any review (row) takes 1 \n",
    "# if the rating of that review is greater than 3.\n",
    "\n",
    "df['reviewPositive'] = np.where(df['overall'] > 3, 1, 0)\n",
    "\n",
    "# Dropping the 'overall' column from the dataframe\n",
    "df.drop(labels=['overall', 'summary'], axis=1, inplace=True)\n",
    "\n",
    "# Dropping null values.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Saving the file as 'balanced_reviews.csv'\n",
    "df.to_csv('binarized_reviews.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
